<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="https://neuropix.github.io//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://neuropix.github.io//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://neuropix.github.io//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="https://neuropix.github.io//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://neuropix.github.io//apple-touch-icon.png">

<link rel="alternate" type="application/rss+xml" href="https://neuropix.github.io/posts/index.xml" title="NeuroPix">
<meta name="description" content=""/>

<title>
    
    Posts | NeuroPix
    
</title>

<link rel="canonical" href="https://neuropix.github.io/posts/"/>












<link rel="stylesheet" href="/assets/combined.min.a6824bbee0d90d5af09fed9b70395ce7076b615e315037455d903314e96ef91b.css" media="all">









  </head>

  

  
  
  

  <body class="auto">

    <div class="content">
      <header>
        

<div class="header">

    

    <h1 class="header-title">NeuroPix</h1>

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /home
            </a>
        </p>
        
      
        <p class="small  bold ">
            <a href="/posts" >
                /posts
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/about" >
                /about
            </a>
        </p>
        
        
    </div>

    

</div>

      </header>

      <main class="main">
        

<div class="list-container">

    
<div class="breadcrumbs">
    
    <a href="/">Home</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a class="breadcrumbs-current" href="/posts/">Posts</a>
</div>


    <h1>Posts</h1>
    

    

    
    
    
    

    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">26 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/raspberry-pi-nas-setup/">
                树莓派网络附加存储设置
            </a>
        </p>

        
        <p class="line-summary"> <p>在这篇文章中，我将分享如何在树莓派上安装 OpenMediaVault（OMV），并将其配置为网络附加存储（NAS）设备。</p>
<h2 id="为什么选择-omv">为什么选择 OMV？</h2>
<p>OpenMediaVault 是一款基于 Debian 的 NAS 解决方案，提供用户友好的界面和丰富的功能，适合各种用户需求。使用树莓派作为 NAS，不仅可以节省空间，还能实现高效的文件共享。</p>
<h2 id="安装步骤">安装步骤</h2>
<h3 id="硬件准备">硬件准备</h3>
<ul>
<li>树莓派 3 或 4</li>
<li>microSD 卡（建议 16GB 或更大）</li>
<li>外接 USB 硬盘（用于存储数据）</li>
<li>电源适配器</li>
</ul>
<h3 id="1-下载-omv-映像">1. 下载 OMV 映像</h3>
<p>访问 <a href="https://www.openmediavault.org/">OpenMediaVault 的官方网站</a> 下载适用于树莓派的映像文件。</p>
<h3 id="2-刻录映像到-microsd-卡">2. 刻录映像到 microSD 卡</h3>
<p>使用工具如 Balena Etcher 将下载的 OMV 映像写入 microSD 卡。</p>
<h3 id="3-插入卡片并启动">3. 插入卡片并启动</h3>
<p>将 microSD 卡插入树莓派，连接外接 USB 硬盘，接通电源启动。</p>
<h3 id="4-配置-omv">4. 配置 OMV</h3>
<ol>
<li>
<p><strong>访问 Web 界面</strong>：
在浏览器中输入 <code>http://&lt;树莓派的IP地址&gt;</code>，进入 OMV 的管理界面。</p>
</li>
<li>
<p><strong>初始设置</strong>：
默认用户名是 <code>admin</code>，密码是 <code>openmediavault</code>。第一次登录后，建议更改密码。</p>
</li>
<li>
<p><strong>添加存储</strong>：
在“存储”部分，选择你的 USB 硬盘，格式化并挂载。</p>
</li>
<li>
<p><strong>设置共享文件夹</strong>：
创建一个共享文件夹，设置权限。</p> </p>
        
    </div>
</div>
    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">26 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/transformer-evolution-and-application/">
                Transformer 架构的演变与应用
            </a>
        </p>

        
        <p class="line-summary"> <h2 id="引言">引言</h2>
<p>在深度学习的历史长河中，Transformer 架构的出现无疑是一个重要的里程碑。自 2017 年由 Vaswani 等人在论文《Attention is All You Need》中提出以来，Transformer 迅速在自然语言处理（NLP）领域崭露头角，并逐渐扩展到计算机视觉、语音识别等多个领域。本文将探讨 Transformer 的演变过程、其在不同应用中的重要性以及未来的发展趋势。</p>
<h2 id="1-transformer-的基本概念">1. Transformer 的基本概念</h2>
<h3 id="11-自注意力机制">1.1 自注意力机制</h3>
<p>自注意力机制是 Transformer 的核心创新之一。它允许模型在处理输入序列时，动态地关注序列中的不同部分，从而捕捉长距离依赖关系。这一机制使得模型能够更加灵活地理解上下文信息。</p>
<h3 id="12-transformer-架构">1.2 Transformer 架构</h3>
<p>Transformer 由编码器（Encoder）和解码器（Decoder）组成：</p>
<ul>
<li><strong>编码器</strong>：将输入序列编码为上下文表示。</li>
<li><strong>解码器</strong>：根据编码器的输出生成目标序列。</li>
</ul>
<figure><img src="/images/transformer-evolution-and-application/transformer-architecture.png"
    alt="Transformer 架构示意图" height="400"><figcaption>
      <h4>Transformer 架构示意图</h4>
    </figcaption>
</figure>

<h2 id="2-transformer-的演变">2. Transformer 的演变</h2>
<h3 id="21-早期模型bert-和-gpt">2.1 早期模型：BERT 和 GPT</h3>
<ul>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>：引入了双向编码，利用 Masked Language Model 进行预训练，广泛应用于文本分类和问答系统。</li>
<li><strong>GPT (Generative Pre-trained Transformer)</strong>：侧重于生成任务，采用单向自回归的方式，适用于文本生成和对话系统。</li>
</ul>
<h3 id="22-最近的发展vision-transformer-vit">2.2 最近的发展：Vision Transformer (ViT)</h3>
<p>Vision Transformer 将 Transformer 架构引入计算机视觉领域，通过将图像划分为固定大小的块，并将其视为序列输入，显著提升了图像分类性能。ViT 的成功表明 Transformer 也可以有效处理视觉数据。</p>
<h3 id="23-其他变种">2.3 其他变种</h3>
<ul>
<li><strong>T5 (Text-to-Text Transfer Transformer)</strong>：将所有 NLP 任务统一为文本到文本的格式，提升了任务间的迁移学习能力。</li>
<li><strong>Swin Transformer</strong>：提出了一种分层结构，能够处理不同分辨率的输入，适用于图像分割和目标检测。</li>
</ul>
<h2 id="3-transformer-的应用">3. Transformer 的应用</h2>
<h3 id="31-自然语言处理">3.1 自然语言处理</h3>
<p>Transformer 已成为 NLP 领域的标准架构，广泛应用于文本生成、机器翻译和情感分析等任务。</p> </p>
        
    </div>
</div>
    

    

    

</div>

      </main>
    </div>

    <footer>
      

    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    



    </footer>
    
  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>