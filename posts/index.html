<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="https://neuropix.github.io//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://neuropix.github.io//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://neuropix.github.io//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="https://neuropix.github.io//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://neuropix.github.io//apple-touch-icon.png">

<link rel="alternate" type="application/rss+xml" href="https://neuropix.github.io/posts/index.xml" title="NeuroPix">
<meta name="description" content=""/>

<title>
    
    Posts | NeuroPix
    
</title>

<link rel="canonical" href="https://neuropix.github.io/posts/"/>












<link rel="stylesheet" href="/assets/combined.min.a6824bbee0d90d5af09fed9b70395ce7076b615e315037455d903314e96ef91b.css" media="all">









  </head>

  

  
  
  

  <body class="auto">

    <div class="content">
      <header>
        

<div class="header">

    

    <h1 class="header-title">NeuroPix</h1>

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /home
            </a>
        </p>
        
      
        <p class="small  bold ">
            <a href="/posts" >
                /posts
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/about" >
                /about
            </a>
        </p>
        
        
    </div>

    

</div>

      </header>

      <main class="main">
        

<div class="list-container">

    
<div class="breadcrumbs">
    
    <a href="/">Home</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a class="breadcrumbs-current" href="/posts/">Posts</a>
</div>


    <h1>Posts</h1>
    

    

    
    
    
    

    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">26 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/clip/">
                CLIP：跨模态学习的突破
            </a>
        </p>

        
        <p class="line-summary"> <p>在深度学习的快速发展中，跨模态学习正逐渐成为一个重要的研究领域。OpenAI 提出的 CLIP（Contrastive Language–Image Pre-training）模型正是这一领域中的一项重要成果。CLIP 的目标是将文本和图像结合在一起，使得计算机能够理解图像与其描述之间的关系。</p>
<h2 id="什么是-clip">什么是 CLIP？</h2>
<p>CLIP 是一种预训练模型，它通过对大量的图像和相应的文本描述进行对比学习，从而学习到图像和文本之间的相互关系。与传统的视觉模型不同，CLIP 不仅关注图像本身，还将图像与相关文本信息结合起来。这种方法使得 CLIP 在多种视觉任务上展现出卓越的性能。</p>
<h2 id="clip-的工作原理">CLIP 的工作原理</h2>
<p>CLIP 的工作流程可以概括为以下几个步骤：</p>
<ol>
<li>
<p><strong>数据收集</strong>：CLIP 使用大量的图像和相应的文本描述进行训练。这些数据来自互联网，包括各种类型的图像和其描述。</p>
</li>
<li>
<p><strong>编码</strong>：模型分别使用两个不同的编码器处理图像和文本。图像通过视觉编码器（通常是 CNN 或 Transformer）进行处理，而文本则通过文本编码器（通常是 Transformer）进行处理。</p>
</li>
<li>
<p><strong>对比学习</strong>：CLIP 通过对比学习的方法，将图像和其描述的嵌入向量映射到同一个空间。在训练过程中，模型会努力最大化图像和文本之间的相似性，同时最小化不相关图像和文本之间的相似性。</p>
</li>
<li>
<p><strong>多任务能力</strong>：经过训练后，CLIP 模型可以处理多种视觉任务，如图像分类、对象检测、图像生成等，而无需针对特定任务进行重新训练。</p>
</li>
</ol>
<h2 id="clip-的应用">CLIP 的应用</h2>
<p>CLIP 的多任务学习能力使其在多个领域取得了显著的成功，以下是一些主要应用：</p>
<ol>
<li>
<p><strong>图像分类</strong>：CLIP 可以根据给定的文本标签进行图像分类，具有极高的灵活性。</p>
</li>
<li>
<p><strong>文本到图像检索</strong>：用户可以输入文本描述，CLIP 会从大量图像中检索出与描述最相关的图像。</p>
</li>
<li>
<p><strong>图像生成</strong>：CLIP 可以与生成模型结合，生成符合文本描述的图像。</p>
</li>
<li>
<p><strong>零样本学习</strong>：由于 CLIP 在训练过程中学习了大量的图像和文本对，它能够在没有明确标签的情况下进行图像分类任务。</p>
</li>
</ol>
<h2 id="结论">结论</h2>
<p>CLIP 作为一种跨模态学习模型，成功地将图像和文本结合在一起，为计算机视觉和自然语言处理领域带来了新的可能性。它的多任务能力和灵活性使其成为一个重要的研究工具，推动了相关领域的进一步发展。随着对 CLIP 模型的深入研究，我们可以期待未来将出现更多的应用和改进。</p>
<p>希望这篇文章能够帮助你了解 CLIP 的基本概念及其应用。如果你对这个话题有任何问题或想法，欢迎在评论区留言与我交流！</p> </p>
        
    </div>
</div>
    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">26 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/introduction-and-applications-of-vision-transformer-vit/">
                视觉 Transformer（ViT）的介绍与应用
            </a>
        </p>

        
        <p class="line-summary"> <p>在过去的几年中，深度学习领域取得了巨大的进展，尤其是在计算机视觉任务中。传统上，卷积神经网络（CNN）是处理图像的主要工具。然而，近年来，视觉 Transformer（ViT）作为一种新的架构，逐渐受到研究人员的关注。</p>
<h2 id="什么是视觉-transformervit">什么是视觉 Transformer（ViT）？</h2>
<p>视觉 Transformer（ViT）是由 Google Research 提出的，它将 Transformer 架构应用于计算机视觉领域。ViT 通过将图像划分为若干个小的 patch，并将这些 patch 线性嵌入到 Transformer 中进行处理，从而实现图像分类等任务。该方法的核心思想是利用 Transformer 的自注意力机制来捕捉图像中的长距离依赖关系。</p>
<h2 id="vit-的主要特点">ViT 的主要特点</h2>
<ol>
<li>
<p><strong>Patch 分割</strong>：ViT 将输入图像划分为固定大小的 patch（例如 16x16），然后将每个 patch 展平并嵌入到一个高维空间中。这一过程将图像转换为一系列向量，为 Transformer 的输入做好准备。</p>
</li>
<li>
<p><strong>位置编码</strong>：由于 Transformer 不具有 CNN 的空间结构感知能力，ViT 引入了位置编码，以便在处理图像时保留每个 patch 的位置信息。</p>
</li>
<li>
<p><strong>自注意力机制</strong>：ViT 利用 Transformer 的自注意力机制，使得模型能够关注图像中的不同区域，从而捕捉到图像中更复杂的特征。</p>
</li>
<li>
<p><strong>预训练与微调</strong>：ViT 通常在大规模数据集上进行预训练，然后在特定任务上进行微调。这种方法在多个计算机视觉基准上取得了显著的性能提升。</p>
</li>
</ol>
<h2 id="vit-的应用">ViT 的应用</h2>
<p>视觉 Transformer 在许多计算机视觉任务中显示出了优异的性能，以下是一些具体应用：</p>
<ol>
<li>
<p><strong>图像分类</strong>：ViT 在大规模图像分类任务上表现出色，如 ImageNet 挑战。</p>
</li>
<li>
<p><strong>目标检测</strong>：将 ViT 与目标检测框架结合，可以有效提高目标检测的准确性。</p>
</li>
<li>
<p><strong>图像分割</strong>：ViT 也被应用于语义分割任务，通过自注意力机制实现更精细的分割效果。</p>
</li>
<li>
<p><strong>生成模型</strong>：ViT 可以用于生成任务，如图像生成和图像超分辨率。</p>
</li>
</ol>
<h2 id="结论">结论</h2>
<p>视觉 Transformer（ViT）作为一种新的架构，正在逐渐改变计算机视觉的研究和应用。它的自注意力机制和高效的特征提取能力使得 ViT 成为解决许多视觉任务的有效工具。随着对 Transformer 架构的深入研究，我们可以期待未来会有更多的创新和改进出现。</p>
<p>希望这篇文章能够帮助你理解视觉 Transformer 的基本概念及其应用。如果你有任何问题或想法，请在评论区留言与我交流！</p> </p>
        
    </div>
</div>
    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">26 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/transformer-evolution-and-application/">
                Transformer 架构的演变与应用
            </a>
        </p>

        
        <p class="line-summary"> <h2 id="引言">引言</h2>
<p>在深度学习的历史长河中，Transformer 架构的出现无疑是一个重要的里程碑。自 2017 年由 Vaswani 等人在论文《Attention is All You Need》中提出以来，Transformer 迅速在自然语言处理（NLP）领域崭露头角，并逐渐扩展到计算机视觉、语音识别等多个领域。本文将探讨 Transformer 的演变过程、其在不同应用中的重要性以及未来的发展趋势。</p>
<h2 id="1-transformer-的基本概念">1. Transformer 的基本概念</h2>
<h3 id="11-自注意力机制">1.1 自注意力机制</h3>
<p>自注意力机制是 Transformer 的核心创新之一。它允许模型在处理输入序列时，动态地关注序列中的不同部分，从而捕捉长距离依赖关系。这一机制使得模型能够更加灵活地理解上下文信息。</p>
<h3 id="12-transformer-架构">1.2 Transformer 架构</h3>
<p>Transformer 由编码器（Encoder）和解码器（Decoder）组成：</p>
<ul>
<li><strong>编码器</strong>：将输入序列编码为上下文表示。</li>
<li><strong>解码器</strong>：根据编码器的输出生成目标序列。</li>
</ul>
<figure><img src="/images/transformer-evolution-and-application/transformer-architecture.png"
    alt="Transformer 架构示意图" height="400"><figcaption>
      <h4>Transformer 架构示意图</h4>
    </figcaption>
</figure>

<h2 id="2-transformer-的演变">2. Transformer 的演变</h2>
<h3 id="21-早期模型bert-和-gpt">2.1 早期模型：BERT 和 GPT</h3>
<ul>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>：引入了双向编码，利用 Masked Language Model 进行预训练，广泛应用于文本分类和问答系统。</li>
<li><strong>GPT (Generative Pre-trained Transformer)</strong>：侧重于生成任务，采用单向自回归的方式，适用于文本生成和对话系统。</li>
</ul>
<h3 id="22-最近的发展vision-transformer-vit">2.2 最近的发展：Vision Transformer (ViT)</h3>
<p>Vision Transformer 将 Transformer 架构引入计算机视觉领域，通过将图像划分为固定大小的块，并将其视为序列输入，显著提升了图像分类性能。ViT 的成功表明 Transformer 也可以有效处理视觉数据。</p>
<h3 id="23-其他变种">2.3 其他变种</h3>
<ul>
<li><strong>T5 (Text-to-Text Transfer Transformer)</strong>：将所有 NLP 任务统一为文本到文本的格式，提升了任务间的迁移学习能力。</li>
<li><strong>Swin Transformer</strong>：提出了一种分层结构，能够处理不同分辨率的输入，适用于图像分割和目标检测。</li>
</ul>
<h2 id="3-transformer-的应用">3. Transformer 的应用</h2>
<h3 id="31-自然语言处理">3.1 自然语言处理</h3>
<p>Transformer 已成为 NLP 领域的标准架构，广泛应用于文本生成、机器翻译和情感分析等任务。</p> </p>
        
    </div>
</div>
    

    

    
    <div class="post-line">

    
    
    
    

    <p class="line-date">25 Sep 2024 </p>

    <div>
        <p class="line-title">
            <a href="/posts/raspberry-pi-nas-setup/">
                树莓派网络附加存储设置
            </a>
        </p>

        
        <p class="line-summary"> <p>在这篇文章中，我将分享如何在树莓派上安装 OpenMediaVault（OMV），并将其配置为网络附加存储（NAS）设备。</p>
<h2 id="为什么选择-omv">为什么选择 OMV？</h2>
<p>OpenMediaVault 是一款基于 Debian 的 NAS 解决方案，提供用户友好的界面和丰富的功能，适合各种用户需求。使用树莓派作为 NAS，不仅可以节省空间，还能实现高效的文件共享。</p>
<h2 id="安装步骤">安装步骤</h2>
<h3 id="硬件准备">硬件准备</h3>
<ul>
<li>树莓派 3 或 4</li>
<li>microSD 卡（建议 16GB 或更大）</li>
<li>外接 USB 硬盘（用于存储数据）</li>
<li>电源适配器</li>
</ul>
<h3 id="1-下载-omv-映像">1. 下载 OMV 映像</h3>
<p>访问 <a href="https://www.openmediavault.org/">OpenMediaVault 的官方网站</a> 下载适用于树莓派的映像文件。</p>
<h3 id="2-刻录映像到-microsd-卡">2. 刻录映像到 microSD 卡</h3>
<p>使用工具如 Balena Etcher 将下载的 OMV 映像写入 microSD 卡。</p>
<h3 id="3-插入卡片并启动">3. 插入卡片并启动</h3>
<p>将 microSD 卡插入树莓派，连接外接 USB 硬盘，接通电源启动。</p>
<h3 id="4-配置-omv">4. 配置 OMV</h3>
<ol>
<li>
<p><strong>访问 Web 界面</strong>：
在浏览器中输入 <code>http://&lt;树莓派的IP地址&gt;</code>，进入 OMV 的管理界面。</p>
</li>
<li>
<p><strong>初始设置</strong>：
默认用户名是 <code>admin</code>，密码是 <code>openmediavault</code>。第一次登录后，建议更改密码。</p>
</li>
<li>
<p><strong>添加存储</strong>：
在“存储”部分，选择你的 USB 硬盘，格式化并挂载。</p>
</li>
<li>
<p><strong>设置共享文件夹</strong>：
创建一个共享文件夹，设置权限。</p> </p>
        
    </div>
</div>
    

    

    

</div>

      </main>
    </div>

    <footer>
      

    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    



    </footer>
    
  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>