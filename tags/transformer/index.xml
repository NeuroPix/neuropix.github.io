<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transformer on NeuroPix</title>
    <link>https://neuropix.github.io/tags/transformer/</link>
    <description>Recent content in Transformer on NeuroPix</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://neuropix.github.io/tags/transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transformer 架构的演变与应用</title>
      <link>https://neuropix.github.io/posts/%E7%A7%91%E7%A0%94/transformer-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E4%B8%8E%E5%BA%94%E7%94%A8/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://neuropix.github.io/posts/%E7%A7%91%E7%A0%94/transformer-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E4%B8%8E%E5%BA%94%E7%94%A8/</guid>
      <description>本文探讨了Transformer架构的演变及其在多个领域的重要性。自2017年Vaswani等人提出Transformer以来，自注意力机制成为其核心创新，使模型能灵活捕捉长距离依赖。早期模型如BERT和GPT引领了自然语言处理的发展，Vision Transformer（ViT）将该架构引入计算机视觉领域并显著提升了图像分类性能。Transformer在自然语言处理、计算机视觉和语音识别等应用中表现出色，未来预计将在多模态学习和实时处理等领域继续创新和发展。</description>
    </item>
    <item>
      <title>视觉 Transformer（ViT）的介绍与应用</title>
      <link>https://neuropix.github.io/posts/%E7%A7%91%E7%A0%94/%E8%A7%86%E8%A7%89-transformervit%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://neuropix.github.io/posts/%E7%A7%91%E7%A0%94/%E8%A7%86%E8%A7%89-transformervit%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8/</guid>
      <description>视觉 Transformer（ViT）是 Google Research 提出的新型计算机视觉架构，它通过将图像分割成小的 patch 并利用 Transformer 的自注意力机制来处理图像，捕捉长距离依赖关系。ViT 的主要特点包括 patch 分割、位置编码和在大规模数据集上的预训练与微调，使其在图像分类、目标检测、图像分割和生成任务等多个计算机视觉领域表现出色。ViT 正在逐渐改变计算机视觉的研究和应用，为未来的创新和改进奠定基础。</description>
    </item>
  </channel>
</rss>
