<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on NeuroPix</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Home on NeuroPix</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Sep 2024 21:47:47 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>树莓派网络附加存储设置</title>
      <link>http://localhost:1313/posts/raspberry-pi-nas-setup/</link>
      <pubDate>Thu, 26 Sep 2024 21:47:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/raspberry-pi-nas-setup/</guid>
      <description>&lt;p&gt;在这篇文章中，我将分享如何在树莓派上安装 OpenMediaVault（OMV），并将其配置为网络附加存储（NAS）设备。&lt;/p&gt;&#xA;&lt;h2 id=&#34;为什么选择-omv&#34;&gt;为什么选择 OMV？&lt;/h2&gt;&#xA;&lt;p&gt;OpenMediaVault 是一款基于 Debian 的 NAS 解决方案，提供用户友好的界面和丰富的功能，适合各种用户需求。使用树莓派作为 NAS，不仅可以节省空间，还能实现高效的文件共享。&lt;/p&gt;&#xA;&lt;h2 id=&#34;安装步骤&#34;&gt;安装步骤&lt;/h2&gt;&#xA;&lt;h3 id=&#34;硬件准备&#34;&gt;硬件准备&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;树莓派 3 或 4&lt;/li&gt;&#xA;&lt;li&gt;microSD 卡（建议 16GB 或更大）&lt;/li&gt;&#xA;&lt;li&gt;外接 USB 硬盘（用于存储数据）&lt;/li&gt;&#xA;&lt;li&gt;电源适配器&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;1-下载-omv-映像&#34;&gt;1. 下载 OMV 映像&lt;/h3&gt;&#xA;&lt;p&gt;访问 &lt;a href=&#34;https://www.openmediavault.org/&#34;&gt;OpenMediaVault 的官方网站&lt;/a&gt; 下载适用于树莓派的映像文件。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2-刻录映像到-microsd-卡&#34;&gt;2. 刻录映像到 microSD 卡&lt;/h3&gt;&#xA;&lt;p&gt;使用工具如 Balena Etcher 将下载的 OMV 映像写入 microSD 卡。&lt;/p&gt;&#xA;&lt;h3 id=&#34;3-插入卡片并启动&#34;&gt;3. 插入卡片并启动&lt;/h3&gt;&#xA;&lt;p&gt;将 microSD 卡插入树莓派，连接外接 USB 硬盘，接通电源启动。&lt;/p&gt;&#xA;&lt;h3 id=&#34;4-配置-omv&#34;&gt;4. 配置 OMV&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;访问 Web 界面&lt;/strong&gt;：&#xA;在浏览器中输入 &lt;code&gt;http://&amp;lt;树莓派的IP地址&amp;gt;&lt;/code&gt;，进入 OMV 的管理界面。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;初始设置&lt;/strong&gt;：&#xA;默认用户名是 &lt;code&gt;admin&lt;/code&gt;，密码是 &lt;code&gt;openmediavault&lt;/code&gt;。第一次登录后，建议更改密码。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;添加存储&lt;/strong&gt;：&#xA;在“存储”部分，选择你的 USB 硬盘，格式化并挂载。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;设置共享文件夹&lt;/strong&gt;：&#xA;创建一个共享文件夹，设置权限。&lt;/p&gt;</description>
    </item>
    <item>
      <title>关于 NeuroPix</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Thu, 26 Sep 2024 21:44:45 +0800</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/about/logo.jpg&#34; height=&#34;200&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;欢迎来到 &lt;strong&gt;NeuroPix&lt;/strong&gt;！在这里，我们将一起探索人工智能的无尽可能性。这个博客不仅是我个人的学习笔记，更是一个分享和交流的社区。无论你是科技领域的老鸟，还是刚刚起步的新手，这里都有你需要的知识和灵感。&lt;/p&gt;&#xA;&lt;p&gt;我相信，技术不仅仅是工具，它是解决问题的钥匙，是创造未来的桥梁。通过 NeuroPix，我希望能与你分享我的思考、经验，以及我对这个快速发展的世界的见解。&lt;/p&gt;&#xA;&lt;p&gt;让我们一起在人工智能的旅程中，发现、学习和成长吧！&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformer 架构的演变与应用</title>
      <link>http://localhost:1313/posts/transformer-evolution-and-application/</link>
      <pubDate>Thu, 26 Sep 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/transformer-evolution-and-application/</guid>
      <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;&#xA;&lt;p&gt;在深度学习的历史长河中，Transformer 架构的出现无疑是一个重要的里程碑。自 2017 年由 Vaswani 等人在论文《Attention is All You Need》中提出以来，Transformer 迅速在自然语言处理（NLP）领域崭露头角，并逐渐扩展到计算机视觉、语音识别等多个领域。本文将探讨 Transformer 的演变过程、其在不同应用中的重要性以及未来的发展趋势。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-transformer-的基本概念&#34;&gt;1. Transformer 的基本概念&lt;/h2&gt;&#xA;&lt;h3 id=&#34;11-自注意力机制&#34;&gt;1.1 自注意力机制&lt;/h3&gt;&#xA;&lt;p&gt;自注意力机制是 Transformer 的核心创新之一。它允许模型在处理输入序列时，动态地关注序列中的不同部分，从而捕捉长距离依赖关系。这一机制使得模型能够更加灵活地理解上下文信息。&lt;/p&gt;&#xA;&lt;h3 id=&#34;12-transformer-架构&#34;&gt;1.2 Transformer 架构&lt;/h3&gt;&#xA;&lt;p&gt;Transformer 由编码器（Encoder）和解码器（Decoder）组成：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;编码器&lt;/strong&gt;：将输入序列编码为上下文表示。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;解码器&lt;/strong&gt;：根据编码器的输出生成目标序列。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/images/transformer-evolution-and-application/transformer-architecture.png&#34;&#xA;    alt=&#34;Transformer 架构示意图&#34; height=&#34;400&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;Transformer 架构示意图&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;h2 id=&#34;2-transformer-的演变&#34;&gt;2. Transformer 的演变&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-早期模型bert-和-gpt&#34;&gt;2.1 早期模型：BERT 和 GPT&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;BERT (Bidirectional Encoder Representations from Transformers)&lt;/strong&gt;：引入了双向编码，利用 Masked Language Model 进行预训练，广泛应用于文本分类和问答系统。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GPT (Generative Pre-trained Transformer)&lt;/strong&gt;：侧重于生成任务，采用单向自回归的方式，适用于文本生成和对话系统。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;22-最近的发展vision-transformer-vit&#34;&gt;2.2 最近的发展：Vision Transformer (ViT)&lt;/h3&gt;&#xA;&lt;p&gt;Vision Transformer 将 Transformer 架构引入计算机视觉领域，通过将图像划分为固定大小的块，并将其视为序列输入，显著提升了图像分类性能。ViT 的成功表明 Transformer 也可以有效处理视觉数据。&lt;/p&gt;&#xA;&lt;h3 id=&#34;23-其他变种&#34;&gt;2.3 其他变种&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;T5 (Text-to-Text Transfer Transformer)&lt;/strong&gt;：将所有 NLP 任务统一为文本到文本的格式，提升了任务间的迁移学习能力。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Swin Transformer&lt;/strong&gt;：提出了一种分层结构，能够处理不同分辨率的输入，适用于图像分割和目标检测。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;3-transformer-的应用&#34;&gt;3. Transformer 的应用&lt;/h2&gt;&#xA;&lt;h3 id=&#34;31-自然语言处理&#34;&gt;3.1 自然语言处理&lt;/h3&gt;&#xA;&lt;p&gt;Transformer 已成为 NLP 领域的标准架构，广泛应用于文本生成、机器翻译和情感分析等任务。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
